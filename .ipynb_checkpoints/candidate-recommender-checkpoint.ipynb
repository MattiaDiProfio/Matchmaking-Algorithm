{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439c29d3",
   "metadata": {},
   "source": [
    "# SkillPilot - A job recommender system for candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec95282",
   "metadata": {},
   "source": [
    "<a id=\"table-of-contents\"></a>\n",
    " ## Table of Contents  \n",
    "- [Project Overview](#project-overview)     \n",
    "- [Preparing the Data](#preparing-the-data) \n",
    "    - [Candidates data cleaning](#candidates-data-cleaning)\n",
    "    - [Jobs data cleaning](#jobs-data-cleaning)\n",
    "- [Exploratory Data Visualization & Analysis](#exploratory-data-viz) \n",
    "    - [Candidates Data Analysis](#candidates-data-analysis)\n",
    "    - [Jobs Data Analysis](#jobs-data-analysis)\n",
    "- [Gale-Shapley Algorithm](#gale-shapley)\n",
    "    - [Performance Benchmark Decorator](#benchmark-decorator)\n",
    "    - [Configuring Control Variables](#control-variables)\n",
    "    - [Performance Metrics & Evaluation](#performance-accuracy)\n",
    "        - [Jobs vs Iterations Evaluation](#jobs-iterations)\n",
    "        - [Run-time vs Input size](#runtime-inputsize)\n",
    "        - [Percentage of Offers vs Input size](#percentage)\n",
    "    - [Run-time Improvements](#runtime-improvements)\n",
    "        - [Population with Assumption](#compute-matrix-v2)\n",
    "        - [Testing Matrix Population Methods](#testing-population-methods)\n",
    "    - [Improving the percentage of offers computed](#improving-offer-pecentage)\n",
    "    - [Conclusion](#gale-shapley-conclusion)\n",
    "        \n",
    "- [K-Nearest Neighbours](#knn)\n",
    "\n",
    "- [Expectation Maximization Algorithm](#expectation-maximization)\n",
    "\n",
    "- [Linear Support Vector Machines](#linear-svm)\n",
    "    - [Exploratory Data Analysis](#svm-data-analysis)\n",
    "    - [Proposed Strategy](#svm-strategy)\n",
    "    - [Constructing the Dataframe for SVC](#svm-df-setup)\n",
    "    - [Implementing the SVM classifier](#svm-implementation)\n",
    "    \n",
    "- [Random Forest](#random-forest)\n",
    "\n",
    "- [LambdaMART Algorithm](#lambda-mart)\n",
    "\n",
    "- [Project Conclusion](#project-conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff62966",
   "metadata": {},
   "source": [
    "<a id=\"project-overview\"></a>\n",
    "## Project Overview\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd73e45b",
   "metadata": {},
   "source": [
    "The aim of this project is to come up with a solution capable of accurately matching candidates suitable for a particular job advertisement. I will proceed by conducting some exploratory data analysis on the (randomly generated) datasets, to then proceed with the implementation of common matchmaking algorithms as well as machine learning regression and classification techniques. \n",
    "Finally, I will analyse the performance of each approach to select a suitable option to carry out the pairing procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae971e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# set matplotlib inline styles\n",
    "%matplotlib inline\n",
    "\n",
    "# load the datasets into pandas dataframes\n",
    "jobs = pd.read_csv('jobs.csv')\n",
    "candidates = pd.read_csv('candidates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b0139d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checkout the head of the jobs dataframe\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b291ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the head of the candidates dataframe\n",
    "candidates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191942c5",
   "metadata": {},
   "source": [
    "<a id=\"preparing-the-data\"></a>\n",
    "## Preparing the Data\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbd111",
   "metadata": {},
   "source": [
    "In this section, both dataframes are prepared for future data visualization and prepared according to the algorithm utilised. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b08e9e",
   "metadata": {},
   "source": [
    "<a id=\"candidates-data-cleaning\"></a>\n",
    "### Candidates data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all NaN values each dataframe column with a more appropriate value\n",
    "candidates[\"Experience\"].fillna(\"None\", inplace=True)\n",
    "candidates.fillna(\"N/A\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca8398",
   "metadata": {},
   "source": [
    "Let's now unify the StudyMode and StudyPattern columns, since they are less likely to be a decisive factor when calculating the relevance score of a candidate for a given job position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374827d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates['StudyProgram'] = candidates[[\"StudyMode\", \"StudyPattern\"]].agg('-'.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71388a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values from the newly created StudyProgram column\n",
    "def clean(program):\n",
    "    program = program.split(\"-\")\n",
    "    study_mode, study_pattern = program[0], program[1]\n",
    "    \n",
    "    if study_mode == \"N/A\" and study_pattern == \"N/A\":\n",
    "        # assume student is campus, fulltime\n",
    "        return \"Campus-FT\"\n",
    "    \n",
    "    if study_mode == \"N/A\":\n",
    "        # assume student in oncampus\n",
    "        return f\"Campus-{study_pattern}\"\n",
    "    \n",
    "    if study_pattern == \"N/A\":\n",
    "        # assume student is fulltime\n",
    "        return f\"{study_mode.capitalize()}-FT\"\n",
    "    \n",
    "    # both entries are specified\n",
    "    return f\"{study_mode.capitalize()}-{study_pattern}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0813eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the unified columns\n",
    "candidates.drop([\"StudyMode\", \"StudyPattern\"], axis=1, inplace=True)\n",
    " \n",
    "# handle null-values in the StudyProgram column\n",
    "candidates[\"StudyProgram\"] = candidates[\"StudyProgram\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8977712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the head of candidates dataframe to see new dataframe\n",
    "candidates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aba133",
   "metadata": {},
   "source": [
    "<a id=\"jobs-data-cleaning\"></a>\n",
    "### Jobs Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbb29a",
   "metadata": {},
   "source": [
    " The round_to_closest function generalizes the MinScore into categories of multiples of 5. This may negatively influence the matchmaking process\n",
    " as some candidates may be wrongfully matched based on the rounded score, however it does simplify the matching process\n",
    " since there are less values the MinScore feature can take on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_closest(x):\n",
    "    # extract the unitary digit\n",
    "    unitary = int(x) % 10\n",
    "    \n",
    "    # extract the decimal digit\n",
    "    decimal = int(x)//10\n",
    "      \n",
    "    # round up or down based on unitary digit\n",
    "    if unitary < 5: return decimal * 10\n",
    "    if unitary == 5: return x\n",
    "    else: return (decimal + 1) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdcd739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the values in the MinScore column to the nearest 5%\n",
    "jobs['MinScore'] = jobs['MinScore'].apply(round_to_closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb10fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the head of the modified dataframe\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9219e",
   "metadata": {},
   "source": [
    "<a id=\"exploratory-data-viz\"></a>\n",
    "## Exploratory Data Analysis & Visualization\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b805e",
   "metadata": {},
   "source": [
    "In this section, the visualization libraries imported at the top of the notebook are put to use to plot both datasets and hopefully discover trends which could be relevant in the later stages of this experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0724b94",
   "metadata": {},
   "source": [
    "<a id=\"candidates-data-analysis\"></a>\n",
    "### Candidates Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec9f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "sns.color_palette(\"PuOr\", as_cmap=True)\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# histogram plot of scores split between different study-programs\n",
    "sns.histplot(\n",
    "    data=candidates, \n",
    "    x=\"Score\", \n",
    "    multiple=\"stack\", \n",
    "    hue='StudyProgram',\n",
    "    edgecolor=\".3\", \n",
    "    bins=50, \n",
    "    linewidth=.5, \n",
    "    kde=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc7ec5",
   "metadata": {},
   "source": [
    "From the above histogram, we can observe that the study-mode and study-pattern of a degree don't seem to affect a student's academic performance. This claim is backed up by the similarity in kernel-density line in the histogram above, as regardless of the study-program candidates tend to have a score between 60% and 85%, with some outliers scoring 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "\n",
    "# histogram plot of scores split between different study-programs\n",
    "chart = sns.countplot(\n",
    "    data=candidates, \n",
    "    x='Course', \n",
    "    palette='RdBu', \n",
    "    orient=\"v\"\n",
    ")\n",
    "\n",
    "# configure labels along the x-axis\n",
    "chart.set_xticklabels(\n",
    "    chart.get_xticklabels(),\n",
    "    rotation=60,\n",
    "    ha=\"right\",\n",
    "    rotation_mode='anchor'\n",
    ")\n",
    "\n",
    "None # hide the label objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81ecd33",
   "metadata": {},
   "source": [
    "From the above countplot, we can see that for this particular batch of candidates, the majority are enrolled in Dentistry-related or Nursing/Medicine degree program, which requires that the corresponding batch of jobs must be rich in opportunities for these students, otherwise there's a risk of many of them going unmatched or matched to a less desirable job position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70479ed5",
   "metadata": {},
   "source": [
    "<a id=\"jobs-data-analysis\"></a>\n",
    "### Jobs Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# countplot of companies grouped according to the minimum scored required for their positions\n",
    "sns.countplot(\n",
    "    data=jobs, \n",
    "    x='MinScore', \n",
    "    palette='Set2',\n",
    "    orient=\"v\"\n",
    ")\n",
    "\n",
    "# display the background grid\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2cfa4d",
   "metadata": {},
   "source": [
    "From the above countplot, we can observe that most positions require candidates to have a minimum score between 80-90%, with around 12 outliers requiring particularly high score of 95%. \n",
    "\n",
    "Comparing this countplot with the one for the student scores, the following can be deduced :\n",
    "- Any student with a score below 70 risks of not getting matched to any internship\n",
    "- The students with a score of 100 are likely to be matched to the positions requiring a 95% score. \n",
    "\n",
    "It is worth noting that a greedy algorithm might fail to compute a stable match, so for example a student with 100% score might be matched to an internship requiring a 70% instead of a more suitable 95% internship. This would also cause students with a score of 70% having their position stolen from the better students, leaving them potentially unmatched. \n",
    "\n",
    "The *Gale-Shapley* algorithm aims to avoid this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee2ca5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# total number of positions per job grouped by field of job\n",
    "positions_per_field = jobs.groupby(\"Field\").sum(numeric_only=True)[\"Positions\"]\n",
    "\n",
    "# total number of students with experience grouped by field type\n",
    "candidates_per_field = candidates[\"Experience\"].value_counts()\n",
    "\n",
    "field_df = pd.DataFrame(positions_per_field).join(candidates_per_field)\n",
    "\n",
    "# create a column to analyse the difference in job supply and demand in each field\n",
    "field_df[\"Supply vs Demand\"] = field_df[\"Positions\"] - field_df[\"Experience\"]\n",
    "\n",
    "# show the dataframe\n",
    "field_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d6a04",
   "metadata": {},
   "source": [
    "By the above analysis we can conclude that for these particular datasets :\n",
    "\n",
    "- Physiotherapy has the highest demand to supply ratio, mostly due to the lower number of available job positions in the field\n",
    "- The remaining fields seem to be abundant in jobs\n",
    "- If this ratio were to be negative for a field, there's a risk of students remaining unmatched or having to accept a position in a field outside their preferred sector.\n",
    "\n",
    "Based on these observations alone, and excluding factors such as a job's MinScore vs a student's Score it appears as if *not* every student will be matched to an internship in their field of expertise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae217d4",
   "metadata": {},
   "source": [
    "<a id=\"gale-shapley\"></a>\n",
    "# Gale-Shapley Algorithm\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81751b7",
   "metadata": {},
   "source": [
    "The stable matching problem, in its most basic form, takes as input equal numbers of two types of participants (*n* job applicants and *n* employers, for example), and an ordering for each participant giving their preference for whom to be matched to among the participants of the other type. A matching pairs each participant of one type with a participant of the other type. A matching is not stable if:\n",
    "\n",
    "- There is an element *A* of the first matched set which prefers some given element *B* of the second matched set over the element to which *A* is already matched, and\n",
    "- *B* also prefers *A* over the element to which *B* is already matched.\n",
    "\n",
    "In other words, a matching is stable when there is no pair *(A, B)* where both participants prefer each other to their matched partners. If such a pair exists, the matching is not stable, in the sense that the members of this pair would prefer to leave the system and be matched to each other, possibly leaving other participants unmatched. A stable matching always exists, and the algorithmic problem solved by the Gale–Shapley algorithm is to find one.\n",
    "\n",
    "The Gale–Shapley algorithm involves a number of \"rounds\" or \"iterations\". In terms of job applicants and employers, it can be expressed as follows : \n",
    "\n",
    "- In each round, one or more employers with open job positions each make a job offer to the applicant they prefer, among the ones they have not yet already made an offer to.\n",
    "- Each applicant who has received an offer evaluates it against their current position (if they have one). If the applicant is not yet employed, or if they receive an offer from an employer they like better than their current employer, they accept the best new offer and become matched to the new employer (possibly leaving a previous employer with an open position). Otherwise, they reject the new offer.\n",
    "- This process is repeated until all employers have either filled their positions or exhausted their lists of applicants.\n",
    "\n",
    "The above algorithm is at the core of the implementation found below, however since the size of the candidates and jobs input sets is most likely to be different, this version of the algorithm only guarantees a portion of the matches computed to be stable, but aims to guarantee that every candidate receives an offer (given that there are enough offers to give out in the first place). \n",
    "\n",
    "This section is then concluded by motivating the adoption of an improved version of the algorithm, which takes the same idea of Gale-Shapley and tailors it to this specific problem and then compares both the runtime efficiency and percentage of jobs matched with the data gathered from the basic version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35823381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# return a score to classify the compatibility of a candidate to a job\n",
    "def compute_compatibility(candidate, job):\n",
    "    compatibility_score = 0\n",
    "    \n",
    "    # check if student has similar experience\n",
    "    if candidate[\"Experience\"] == job[\"Field\"]: compatibility_score += 1\n",
    "    else: compatibility_score += 0.5\n",
    "    \n",
    "    # assign a reduced factor based on how far off the MinScore the candidate's score is\n",
    "    candidate_score = candidate[\"Score\"]\n",
    "    job_minscore = job[\"MinScore\"]\n",
    "    \n",
    "    # candidate will prefer job whose MinScore is closer to their achieved grade \n",
    "    if candidate_score <= 0.9 * job_minscore or candidate_score >= 1.1 * job_minscore: compatibility_score += 1\n",
    "    elif candidate_score <= 0.75 * job_minscore or candidate_score >= 1.25 * job_minscore: compatibility_score += 0.5\n",
    "    else: compatibility_score += 0.25\n",
    "        \n",
    "    # account for a candidate preferring location, pay, company title etc.\n",
    "    compatibility_score += random.random()\n",
    "    \n",
    "    return round(compatibility_score, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b09b5f",
   "metadata": {},
   "source": [
    "<a id=\"benchmark-decorator\"></a>\n",
    "## Performance Benchmark Decorator\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "# decorator function to measure the time performance of function fn\n",
    "def benchmark(fn):\n",
    "\n",
    "    @wraps(fn)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        \n",
    "        # save time snapshots before and after function call\n",
    "        start_time = time()\n",
    "        result = fn(*args, **kwargs)\n",
    "        end_time = time()\n",
    "        \n",
    "        # display time elapsed and return result of fn call\n",
    "        print(f'Executed {fn.__name__}, Time Elapsed : {round(end_time - start_time, 3)} seconds')\n",
    "        return result\n",
    "    \n",
    "    # return the wrapper function\n",
    "    return wrapper "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4194807",
   "metadata": {},
   "source": [
    "We create a computability matrix, where each row is a student and each column a job position. \n",
    "The entry at position *(i, j)* is the compatibility score between student *i* and job *j*. \n",
    "The table will have *m x n* entries, where *m* is the number of candidates and *n* the number of representative jobs available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5cc2d2",
   "metadata": {},
   "source": [
    "<a id=\"control-variables\"></a>\n",
    "## Configuring Control Variables\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1043fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control variables used by the Gale-Shapley algorithm\n",
    "total_job_titles = len(jobs)\n",
    "total_jobs_available = jobs.loc[:total_job_titles, \"Positions\"].sum()\n",
    "total_candidates = len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921557e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the tqdm module to implement an real-time progress bar for the loop below\n",
    "import sys\n",
    "from time import sleep\n",
    "from tqdm import trange\n",
    "\n",
    "# populate the compatibility matrix using the jobs and candidates dataframe\n",
    "@benchmark\n",
    "def populate_compatibility_matrix(matrix, candidates, jobs):\n",
    "    for i in trange(len(candidates), file=sys.stdout, colour='GREEN'):\n",
    "        for j in range(len(jobs)): \n",
    "            matrix.loc[(i, j)] = compute_compatibility(candidates.loc[i], jobs.loc[j])\n",
    "        sleep(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3c837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute the preference matrix for the given dataframes\n",
    "def compute_preference_matrix(candidates, jobs):\n",
    "    \n",
    "    # use jobs and candidates indices instead of fullname and company as it guarantees uniqueness\n",
    "    jobs_indices = [ i for i in range(len(jobs)) ]\n",
    "    candidate_indices = [ i for i in range(len(candidates)) ]\n",
    "\n",
    "    # create the compatibility dataframe/matrix\n",
    "    compatibility = pd.DataFrame(0, index=candidate_indices, columns=jobs_indices)\n",
    "    compatibility = compatibility.rename_axis(index='Candidate IDs', columns='Job IDs')\n",
    "\n",
    "    # populate the compatibility matrix\n",
    "    print(\"Populating the Compatibility matrix...\")\n",
    "    populate_compatibility_matrix(compatibility, candidates, jobs)\n",
    "    print(\"Population operation completed.\")\n",
    "    \n",
    "    return compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a296fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a list of jobs, return the index of a job with offers to still give out, or -1 if none are found\n",
    "def find_job(company_ids):\n",
    "    for i in range(len(company_ids)):\n",
    "        if company_ids[i] >= 0: return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f994653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suitable_candidates(company_index, compatibility_matrix):\n",
    "    # retrieve the column with key of company_index from the compatibility matrix\n",
    "    suit_cands = [(i, compatibility_matrix[company_index][i]) for i in range(len(compatibility_matrix[company_index]))]\n",
    "    \n",
    "    # sort the candidates by their compatibility score descending, so company makes offer to most relevant candidates first\n",
    "    suit_cands.sort(key = lambda x: x[1])\n",
    "    \n",
    "    return suit_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all the offers made in a user-readable format\n",
    "def format_pairings(offers):\n",
    "    for candidate_id in offers.keys():\n",
    "        candidate_name = candidates.loc[candidate_id, \"Fullname\"]\n",
    "        job_title = \"N/A\" if offers[candidate_id][0] == None else jobs.loc[offers[candidate_id][0], \"Title\"]\n",
    "        print(f'{candidate_name} -> {job_title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67111fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark\n",
    "# run the gale-shapley algorithm on the input candidates and jobs sets\n",
    "def gale_shapley(company_ids, offers, compatibility_matrix, available_positions, max_iterations=10000):\n",
    "    \n",
    "    # keep track of number of companies fulfilled at each iteration\n",
    "    fulfillments = []\n",
    "    iterations = 0\n",
    "    \n",
    "    # trigger time-out when algorithm reaches a stagnant point\n",
    "    while iterations < max_iterations:\n",
    "        \n",
    "        # find a company with job offers to give out\n",
    "        company_id = find_job(company_ids)\n",
    "        \n",
    "        # stop condition when all companies have given out jobs\n",
    "        if company_id == -1: break\n",
    "            \n",
    "        # job J with positions still to fill-out\n",
    "        j = company_ids[company_id]\n",
    "        \n",
    "        # find most compatible candidate who company j has not offered a job to yet\n",
    "        comps = suitable_candidates(j, compatibility_matrix)\n",
    "        \n",
    "        # check whether all students reject this company\n",
    "        all_reject = True\n",
    "        \n",
    "        for candidate in comps:\n",
    "            candidate_id = candidate[0]\n",
    "            \n",
    "            # make an offer to this candidate\n",
    "            if j not in offers[candidate_id][1]:\n",
    "                \n",
    "                # check if candidate has no offer yet\n",
    "                if offers[candidate_id][0] == None:\n",
    "                    \n",
    "                    # make the offer \n",
    "                    offers[candidate_id][0] = j\n",
    "                    \n",
    "                    # change reject status\n",
    "                    all_reject = False\n",
    "                    \n",
    "                    # reduce number of jobs available for job j\n",
    "                    available_positions[j] -= 1\n",
    "                    \n",
    "                    # check number of positions \n",
    "                    if available_positions[j] == 0:\n",
    "                        \n",
    "                        # all positions have been filled\n",
    "                        company_ids[j] = -1\n",
    "                        break\n",
    "                        \n",
    "                    # make sure this company cannot make another offer to the same candidate\n",
    "                    offers[candidate_id][1].append(company_id)\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    # make offer, then candidate chooses the company they compare best with\n",
    "                    k = offers[candidate_id][0] # id of company candidate has an offer from\n",
    "                    prev_offer_score = compatibility_matrix.loc[candidate_id, k]\n",
    "                    curr_offer_score = compatibility_matrix.loc[candidate_id, j]\n",
    "                    \n",
    "                    if curr_offer_score > prev_offer_score:\n",
    "                        \n",
    "                        # candidate accepts new offer \n",
    "                        offers[candidate_id][0] = j\n",
    "                        \n",
    "                        # change reject status\n",
    "                        all_reject = False\n",
    "                        \n",
    "                        # old offer now becomes free\n",
    "                        available_positions[k] += 1\n",
    "                        \n",
    "                        # current job position is not available to other candidates, so decrement\n",
    "                        available_positions[j] -= 1\n",
    "                        \n",
    "                        # check if old job has new positions free\n",
    "                        if available_positions[k] == 1: company_ids[k] = k    \n",
    "                            \n",
    "                        # check if new job has been completely filled out\n",
    "                        if available_positions[j] == 0: company_ids[j] = -1  \n",
    "                            \n",
    "                    else:\n",
    "                        # candidate rejects new offer - add this company to the banned list for this candidate\n",
    "                        offers[candidate_id][1].append(company_id)\n",
    "                    break\n",
    "                    \n",
    "        # if company rejected by all students, then remove it from being considered next\n",
    "        if all_reject: company_ids[j] = -1\n",
    "            \n",
    "        # save number of fulfilled companies after current iteration\n",
    "        fulfillments.append(company_ids.count(-1))\n",
    "        iterations += 1\n",
    "        \n",
    "    if iterations >= max_iterations: print(\"Termination due to time-out\")\n",
    "        \n",
    "    return [offers, fulfillments]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d1521e",
   "metadata": {},
   "source": [
    "<a id=\"performance-accuracy\"></a> \n",
    "## Performance Metrics & Evaluation\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ef71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# run the Gale-Shapley algorithm for a range of candidates and jobs\n",
    "def run_gale_shapley(number_of_candidates, number_of_jobs, verbose):\n",
    "    \n",
    "        start_time = time()\n",
    "        \n",
    "        print(f\"\\nRunning Gale-Shapley for {number_of_candidates} candidates and {number_of_jobs} jobs...\")\n",
    "    \n",
    "        # reduce size of candidates and jobs dataframes \n",
    "        candidates_dataframe = candidates.loc[:number_of_candidates]\n",
    "        jobs_dataframe = jobs.loc[:number_of_jobs]\n",
    "        \n",
    "        # compute the compatibility matrix\n",
    "        compute_matrix_start_time = time()\n",
    "        compatibility_matrix = compute_preference_matrix(candidates_dataframe, jobs_dataframe)\n",
    "        compute_matrix_elapsed_time = round(time() - compute_matrix_start_time, 1)\n",
    "        \n",
    "        # keeps track of companies with job offers to still give out \n",
    "        company_ids = compatibility_matrix.columns.tolist()\n",
    "\n",
    "        # keeps track of the offers made so far, candidate_id : (current_offer_company_id, [refusing_company_id1, ...])\n",
    "        offers = { candidate_id : [None, []] for candidate_id in range(number_of_candidates + 1) }\n",
    "\n",
    "        # keeps track of the number of positions left per job\n",
    "        available_positions = [ jobs_dataframe.loc[job_id, \"Positions\"] for job_id in range(len(jobs_dataframe)) ]\n",
    "        \n",
    "        # compute the total number of positions across number_of_jobs jobs\n",
    "        total_jobs = sum(available_positions)\n",
    "        \n",
    "        # run the Gale-Shapley algorithm between the jobs and candidates dataset\n",
    "        offers, fulfillments = gale_shapley(company_ids, offers, compatibility_matrix, available_positions)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nOffers computed for {number_of_candidates} candidates and {number_of_jobs} jobs > \", format_pairings(offers))\n",
    "        \n",
    "        # store number of input candidates and input jobs alongside number of matches constructed by gale_shapley\n",
    "        candidates_with_offers = len([ candidate_id for candidate_id in offers.keys() if offers[candidate_id] != 1 ])\n",
    "        jobs_assigned = candidates_with_offers\n",
    "        percentage_metrics = (number_of_candidates, total_jobs, min(candidates_with_offers, number_of_candidates), min(total_jobs, jobs_assigned))\n",
    "        \n",
    "        # compute iterations of this algorithm call\n",
    "        iterations = len(fulfillments)\n",
    "        \n",
    "        # compute time of execution\n",
    "        elapsed_time = round(time() - start_time, 2)\n",
    "        \n",
    "        return (fulfillments[::-1], iterations, percentage_metrics, elapsed_time, compute_matrix_elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcd1c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute lineplots for the performance of the algorithm over a range of candidates and jobs\n",
    "performance_data = [ run_gale_shapley(i, j, verbose=False) for j in range(25, 125, 25) for i in range(100, 1100, 100) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad698937",
   "metadata": {},
   "source": [
    "<a id=\"jobs-iterations\"></a>\n",
    "### Jobs Remaining vs Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853bbacf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set the style for the plot\n",
    "plt.figure(figsize=(21, 10))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# configure multi-level index for the dataframe, such that each 100 candidates have 25, 50, 75, 100 jobs \n",
    "iterations_outer_index = [ i for i in range(100, 1100, 100) ]\n",
    "iterations_inner_index = [ i for i in range(25, 125, 25) ]\n",
    "iterations_multi_index = pd.MultiIndex.from_product([iterations_outer_index, iterations_inner_index], names=['Candidates', 'Jobs Advertised'])\n",
    "\n",
    "# create a DataFrame with the MultiIndex for the Iterations data\n",
    "iterations_data = {\n",
    "    'Iterations' : [ data_tuple[1] for data_tuple in performance_data ],\n",
    "    'Jobs Remaining' : [ data_tuple[0] for data_tuple in performance_data ],\n",
    "}\n",
    "\n",
    "iterations_df = pd.DataFrame(data=iterations_data, index=iterations_multi_index)\n",
    "\n",
    "for i in range(len(iterations_df)):\n",
    "    curr_row = iterations_df.iloc[i]\n",
    "    \n",
    "    # convert the 'Jobs Remaining' column to a list of lists\n",
    "    jobs_remaining_list = curr_row['Jobs Remaining']\n",
    "\n",
    "    # create a DataFrame for the current row\n",
    "    df_curr_row = pd.DataFrame(\n",
    "        {'Iterations': range(1, len(jobs_remaining_list) + 1), \n",
    "         'Jobs Remaining': jobs_remaining_list}\n",
    "    )\n",
    "    \n",
    "    # create the line plot\n",
    "    sns.lineplot(data=df_curr_row, x='Iterations', y='Jobs Remaining')\n",
    "    \n",
    "# set plot labels and title\n",
    "plt.title('Jobs Remaining vs Iterations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Jobs Remaining')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2b9a2",
   "metadata": {},
   "source": [
    "From the above visualization, we can see that the algorithm behaves in a logarithmic way, and in all cases either all jobs are assigned to candidates or all jobs are considered at least once by the algorithm. \n",
    "\n",
    "I believe this behaviour is a result of the *all_reject* control variable in the *gale_shapley* methods, as this ensures that if a job position *j* is rejected by all candidates on iteration *x* of the algorithm, then it will be discarded by any future iteration *y*, so *j* has one \"pass\" of the entire set of candidates to be assigned, otherwise it becomes a reject job.\n",
    "\n",
    "In conclusion, the use of a single-scan approach to assign job *j* guarantees an extremely fast algorithm [1], however the % of jobs assigned tends to be unacceptably low, as indicated by the chart below titled *Jobs Assigned % per Number of Candidates*, but an optimization can be applied which guarantees 100% matching rate, at the expense of a slight increase in runtime. See the subsection titled *Improving the percentage of jobs assigned* for more details.\n",
    "\n",
    "[1] In fact most of the computational time of the *run_gale_shapley* driver function is taken up computing the compatibility matrix for the input datasets, so adopting memoization techniques to expand the matrix based on the previous one rather than repopulating it each time would drastically improve the speed of this function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb82f84c",
   "metadata": {},
   "source": [
    "<a id=\"runtime-inputsize\"></a> \n",
    "### Run-time vs Input size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6532f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "\n",
    "time_outer_index = [ i for i in range(100, 1100, 100) ]\n",
    "time_inner_index = [ i for i in range(25, 125, 25) ]\n",
    "time_multi_index = pd.MultiIndex.from_product(\n",
    "    [time_outer_index, time_inner_index], \n",
    "    names=['Candidates', 'Jobs Advertised']\n",
    ")\n",
    "\n",
    "# create a DataFrame with the MultiIndex for the Time Elapsed data\n",
    "time_data = {'Time Elapsed' : [ data_tuple[3] for data_tuple in performance_data ] }\n",
    "time_df = pd.DataFrame(data=time_data, index=time_multi_index)\n",
    "\n",
    "# plot the above dataframe\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "time_chart = sns.lineplot(\n",
    "    data=time_df.reset_index(), \n",
    "    x='Jobs Advertised', \n",
    "    y='Time Elapsed', \n",
    "    palette='Paired', \n",
    "    hue='Candidates', \n",
    "    marker='o'\n",
    ")\n",
    "\n",
    "plt.title('run_gale_shapley - Time Elapsed')\n",
    "plt.xlabel('Jobs')\n",
    "plt.ylabel('Time Elapsed (s)')\n",
    "\n",
    "sns.move_legend(time_chart, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e1e3de",
   "metadata": {},
   "source": [
    "The above chart suggests that the *run_gale_shapley* method is linear in nature, as the it seems to scale linearly to the increasing number of jobs and is independant of the size of the candidates pool. This makes sense, considering that the underlying algorithm will iterate *n x m* times where *n* is the size of the jobs input set and *m* the size of the candidates set. \n",
    "\n",
    "Note however that if *m* approaches *n* the overall time complexity of the algorithm will be *O(n^2)*, but in such case the algorithm would likely terminate before going through *n^2* iterations, since all job offers will be given out before this is the case.\n",
    "\n",
    "The runtime of this function can be further improved by speeding up the time taken to compute the compatibility matrix and sorting the Series of candidates associated with job *j*, such that the most compatible candidate will be likely to be matched earlier with their 1st choice job position and excluded from the next iteration, as there's no reason for them to give up their current offer for another one guaranteed to be less satisfactory. Formally, if candidate *c* is the one at index 0 in the Series for job *j*, then *compatibility(c) >= compatibility(c')*, where *c'* is at index 1+ so assigning job *j* to *c'* would not benefit neither *c* or *j* and therefore this approach to the pairing problem guaranteed a stable-match [1] in the first generation of the algorithm. [2]\n",
    "\n",
    "[1] The definition of a stable-match can be found at the top of the Gale-Shapley section.\n",
    "[2] To better understand the term \"generation\", please consult the section where I work on improving the time efficiency and accuracy of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32b133",
   "metadata": {},
   "source": [
    "<a id=\"percentage\"></a>\n",
    "### Percentage of Offers vs Input Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4be4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# create multi-level index for the dataframe\n",
    "percentage_outer_index = [ i for i in range(100, 1100, 100) ]\n",
    "percentage_inner_index = [ i for i in range(25, 125, 25) ]\n",
    "percentage_multi_index = pd.MultiIndex.from_product(\n",
    "    [percentage_outer_index, percentage_inner_index], \n",
    "    names=['Candidates', 'Jobs Advertised']\n",
    ")\n",
    "\n",
    "# create a dataframe with the MultiIndex for the Assignment percentage data\n",
    "percentage_data = {\n",
    "    'Assigned Candidates %' : [ round(100 * data_tuple[2][2]/data_tuple[2][0], 1) for data_tuple in performance_data ],\n",
    "    'Assigned Jobs %' : [ round(100 * data_tuple[2][3]/data_tuple[2][1], 1) for data_tuple in performance_data ]\n",
    "            }\n",
    "\n",
    "percentage_df = pd.DataFrame(data=percentage_data, index=percentage_multi_index)\n",
    "\n",
    "# Plot the above dataframe\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "percentage_chart = sns.lineplot(\n",
    "    data=percentage_df.reset_index(), \n",
    "    x='Jobs Advertised', \n",
    "    y='Assigned Jobs %', \n",
    "    palette='Paired', \n",
    "    hue='Candidates', \n",
    "    marker='o'\n",
    ")\n",
    "\n",
    "plt.title('Jobs Assigned % per Number of Candidates')\n",
    "plt.xlabel('Jobs')\n",
    "plt.ylabel('Assigned Jobs %')\n",
    "\n",
    "sns.move_legend(percentage_chart, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad1cf2",
   "metadata": {},
   "source": [
    "From the above graph, we can conclude that the percentage of jobs assigned to candidates varies drastically between each of the inputs, but an increase in percentage can be observed in all test cases except for input sets of 300 or 800 candidates. This behaviour is most likely to be caused by characteristics specific to the input datasets rather than the decision making within the algorithm. \n",
    "\n",
    "Overall it appears as if the percentage of jobs assigned tends to increase as the number of jobs available increases, and this behaviour seems to be consistent regarless of the size of the candidate pool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ecbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what the percentage_df indicates about the performance of the algorithm\n",
    "percentage_df[percentage_df[\"Assigned Jobs %\"] < 100.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8026bb3b",
   "metadata": {},
   "source": [
    "<a id=\"runtime-improvements\"></a>\n",
    "## Run-time Improvements\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1741a667",
   "metadata": {},
   "source": [
    "The main aspects this improvement aims to target is to reduce the upfront cost of computing the compatibility matrix by adopting caching techniques and reduce the overall runtime of the matching process. We will explore three different approaches to populating the compatibility matrix for a specific set of inputs and then plot the runtimes to see if caching the previously computed submatrix yields faster execution time.\n",
    "\n",
    "Reducing the time to compute the matrix can be done by adding rows and columns to a matrix computed for a smaller dataset. For example, the compatibility matrix for an input of 500 candidates and 50 jobs can be computed by populating the compatibility score for the extra 100 candidates against the same 50 jobs instead of re-computing the score for the same 400 candidates again, and then for the 100 new candidates. Note that this approch only improves the time complexity and doesn't affect the space complexity, moreover the time complexity to compute the matrix with the current approach is *O((m x n) ^ 2)* due to the repeated computations, but the amortised time complexity with memoization will be *O(m x n)*, since we are looking up the values from the previous set of inputs in *O(1)* time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the entire dataframes for quick referencing when working with them\n",
    "candidates_df = candidates\n",
    "jobs_df = jobs\n",
    "\n",
    "# define a dataframe to represent the compatibility matrix, whose size can be at most m * n\n",
    "matrix = pd.DataFrame(\n",
    "    -1, \n",
    "    index=[ i for i in range(len(candidates_df)) ],\n",
    "    columns=[ j for j in range(len(jobs_df)) ]).rename_axis(index='Candidate IDs', columns='Job IDs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0beca1",
   "metadata": {},
   "source": [
    "<a id=\"compute-matrix-v2\"></a>\n",
    "### Modification - Computing the Compatibility matrix with pre-population assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabb295",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# populate subsection of matrix confined by rows last_row : curr_row and columns last_col : curr_col\n",
    "def populate_compatibility_matrix_v2(candidates, jobs, matrix, curr_row, last_row, curr_col, last_col):\n",
    "    for i in range(curr_row - last_row, curr_row):\n",
    "        for j in range(curr_col - last_col, curr_col):\n",
    "            matrix.loc[i, j] = compute_compatibility(candidates.loc[i], jobs.loc[j])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# use the previously computed performance data from the run_gale_shapley method\n",
    "populate_compatibility_matrix_v1_times = [ data_point[4] for data_point in performance_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd426858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test time elapsed to populate matrix section by section, assuming pre-population\n",
    "populate_compatibility_matrix_v2_times = []\n",
    "for i in range(100, 1001, 100):\n",
    "    start_time = time()\n",
    "    for j in range(25, 101, 25):\n",
    "        matrix = populate_compatibility_matrix_v2(candidates_df, jobs_df, matrix, i, 100, j, 25)\n",
    "    elapsed_time = round(time() - start_time, 1)\n",
    "    populate_compatibility_matrix_v2_times.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb096c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_compatibility_matrix_v3_times = []\n",
    "# compute the entire matrix in one scan, computation done beforehand instead of on-demand\n",
    "start_time = time()\n",
    "for i in range(len(candidates)):\n",
    "    for j in range(len(jobs)):\n",
    "        matrix.loc[i, j] = compute_compatibility(candidates.loc[i], jobs.loc[j])\n",
    "elapsed_time = round(time() - start_time, 1)\n",
    "\n",
    "# we append the result of running the entire loop 10 times (100, 200... 1000 candidates) each time, \n",
    "# since the inner loop runs in 0.1s on average\n",
    "for i in range(10):\n",
    "    populate_compatibility_matrix_v3_times.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07b3cf",
   "metadata": {},
   "source": [
    "<a id=\"testing-population-methods\"></a>\n",
    "### Testing Matrix Population Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter times from the performance_data received from the run_gale_shapley method to contain time to compute all jobs per 100 candidates\n",
    "filtered_populate_compatibility_matrix_v1_times = [ round(sum(populate_compatibility_matrix_v1_times[i : i + 3]),1) for i in range(len(populate_compatibility_matrix_v1_times)) if i % 4 == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = {\n",
    "    'Candidates' : [ i for i in range(100, 1001, 100) ],\n",
    "    'populator_v1' : filtered_populate_compatibility_matrix_v1_times,\n",
    "    'populator_v2' : populate_compatibility_matrix_v2_times,\n",
    "    'populator_v3' : populate_compatibility_matrix_v3_times,\n",
    "}\n",
    "\n",
    "# create a dataframe to store the time taken by each approach for x number of candidates \n",
    "populate_compatibility_matrix_times_df = pd.DataFrame(time_data)\n",
    "\n",
    "populate_compatibility_matrix_times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce091e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# plot the lines\n",
    "sns.lineplot(x='Candidates', y='populator_v1', data=populate_compatibility_matrix_times_df, label='populator_v1', marker='o')\n",
    "sns.lineplot(x='Candidates', y='populator_v2', data=populate_compatibility_matrix_times_df, label='populator_v2', marker='o')\n",
    "sns.lineplot(x='Candidates', y='populator_v3', data=populate_compatibility_matrix_times_df, label='populator_v3', marker='o')\n",
    "\n",
    "# set labels and title\n",
    "plt.xlabel('Candidates')\n",
    "plt.ylabel('Time Elapsed (s)')\n",
    "plt.title('Time elapsed to compute Compatibility Matrix by populator version')\n",
    "\n",
    "# show the legend\n",
    "plt.legend()\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3af96",
   "metadata": {},
   "source": [
    "From the above line plot, we can conclude that the fastest method to compute the Compatibility Matrix for a problem instance is the one outlined by the *populate_compatibility_matrix_v2* method, where for each index input we search for the last populated row index, say *i* and within that row we search for the last populated column index, say *j*.\n",
    "The slowest approach was the one adopted by the *populate_compatibility_matrix_v1* method, since it re-computes the entire matrix every time a matching query has to be carried out.\n",
    "\n",
    "In this case, these indices are precisely 100 rows above and 25 columns to the left of each input point, since these are computed by nested for loops with step size of 100 and 25 respectively. **Recall** however, that this method's efficiency only works if the search for *i* or *j* terminates before reaching the beginning of the first row or column, namely indices 0. Otherwise, this approach yields *O(n^2)* complexity since for each index *i* or *j* we search backwards *i* and *j* rows/columns.\n",
    "\n",
    "To compute the entire matrix ahead, around 35-40 seconds were required. In conclusion, when we are trying to improve the time complexity (notice that the space complexity is the same across all instances, namely *O(m x n)* for *m* candidates and *n* jobs) : \n",
    "- If we are trying to populate a subsection of a matrix partially populated, it is slightly more efficient to compute the subsection based on the assumption that the previous subsection has been populated\n",
    "- If we have a lot of matching queries to execute and the maximum number of candidates and jobs is known in advance, compute the entire matrix in *O(m x n)* time and access the compatibility values in *O(1)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668817f3",
   "metadata": {},
   "source": [
    "<a id=\"improving-offer-pecentage\"></a>\n",
    "## Improving the percentage of offers computed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c17f62",
   "metadata": {},
   "source": [
    "Except for some edge cases, the percentage of jobs fully exhausted (i.e. all of its positions are filled) is usually less than 100%. This might be due to several factors, such as a particular job being \"banned\" from a succeeding iteration of the algorithm if no candidate was willing to accept the offer made during the current round. \n",
    "\n",
    "An approach which could be used to maximize the percentage of jobs assigned relies on one simple concept, for us humans at least, which is that a candidate in a competitive pool would much rather have an offer from a company which was not their first choice rather than end up with no offers at the end of the recruitment cycle due to their preferences. \n",
    "\n",
    "In the scope of the Gale-Shapley algorithm, this concept would be implemented through simple modifications.\n",
    "\n",
    "1. The *compute_compatibility(candidate, job)* function will now take in a 3rd parameter *alpha* which denotes how many attributes are included in the computation of the score. For example is *alpha* = 0, then all attributes are involved and if *alpha* = n (number of attributes) then the score output defaults to 0.0\n",
    "\n",
    "2. The *run_gale_shapley(...)* function will now do the following : \n",
    "    - set *alpha* to 0\n",
    "    - execute Gale-Shapley on the input sets\n",
    "    - exclude the candidates and jobs members of an offer from the input sets\n",
    "    - increase *alpha* by 1 \n",
    "    - repeat Gale-Shapley on this filtered data set until either input set is empty (i.e. jobs = None or candidates = None).\n",
    "    \n",
    "With these modifications in place, a 100% offer-rate is guaranteed, since the compatibility scores of each (candidate, job) pair will eventually converge to 0.0 and the algorithm will assign the remaining entites on a first-come, first-serve basis until the stopping condition is met.\n",
    "\n",
    "Note however, that candidates and jobs matched in round *i* are more likely to be satisfied with their pairing than two entites matched in round *i+1* since their compatibility score is likely to be close to the one of other entities in the same input sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0c048",
   "metadata": {},
   "source": [
    "<a id=\"gale-shapley-conclusion\"></a>\n",
    "## Conclusion\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703209ae",
   "metadata": {},
   "source": [
    "In conclusion, the variant of the Gale-Shapley algorithm implemented in this subsection is a reliable approach to automating the matchmaking process between a set of candidates to a set of job offers. The main advantage of using this offline pairing strategy is that a stable match is guaranteed between the two input sets, with candidates left without an offer being the least qualified for the entire pool of available jobs since by nature, the algorithm will compare the current job it is trying to assign to the offer held by the candidate it is currently considering and assign them the job with maximal compatibility score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66328c6b",
   "metadata": {},
   "source": [
    "<a id=\"knn\"></a> <br>\n",
    "# K-Nearest Neighbours\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5012dd59",
   "metadata": {},
   "source": [
    "<a id=\"expectation-maximization\"></a> <br>\n",
    "# Expectation Maximization Algorithm\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5545e49b",
   "metadata": {},
   "source": [
    "<a id=\"linear-svm\"></a> <br>\n",
    "# Linear Support Vector Machines\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150926ab",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "<a id=\"svm-strategy\"></a> <br>\n",
    "### Proposed Strategy for the SVM model\n",
    "\n",
    "- The task at hand is to create a model capable of predicting whether an offer between a candidate and a job is likely to be accepted by the candidates involved. If the SVM classifier redeems the offer as likely to be accepted, then it will select it for further operations, otherwise a rejection will happen.\n",
    "\n",
    "- I plan on training the model using past offer data, instead of using the compatibility function like the one used in the Gale-Shapley section. Each entry in the training dataframe will have the following (or similar) format : \n",
    "\n",
    "| Candidate ID | Job ID      | Candidate GPA | Job Minimum GPA | Compatibility Score | ...          | Offer Accepted |\n",
    "| -----------  | ----------- | -----------   | -----------     | -----------         | -----------  | -----------    |\n",
    "| 58           | 22          | 78            | 63              | 2.3                 | ...          | YES            |\n",
    "| 29           | 68          | 66            | 80              | 1.6                 | ...          | NO             |\n",
    "\n",
    "- The model will then classify an incoming offer based on the numerical features from the dataframe, such as GPAs and Compatibility score and label the offer as \"promising\" or \"not-promising\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ed3be",
   "metadata": {},
   "source": [
    "<a id=\"svm-data-analysis\"></a> <br>\n",
    "### Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1684136f",
   "metadata": {},
   "source": [
    "In this subsection, I will generate a plot of the three main features I plan on using to develop a Support Vector Classifier : the candidate's score (or GPA), the job's minimum score required, and the compatibility score of the candidate and job based on non-numerical attributes, named *alpha*.\n",
    "In addition, I will plot a heatmap of the compatibility matrix generated for a particular input set to see if there are any patterns hidden within which could help gather insight while developing the SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the candidates and jobs dataset for plotting purposes \n",
    "svm_candidates = candidates.iloc[:25]\n",
    "svm_jobs = jobs[:25]\n",
    "\n",
    "# compute preference matrix for the initial candidates and jobs input sets, after data cleaning\n",
    "matrix = compute_preference_matrix(svm_candidates, svm_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf09d77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "sns.heatmap(matrix, cmap=\"plasma\", annot=True, linewidth=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9c962",
   "metadata": {},
   "source": [
    "From the heatmap above, it is clear that for the subset of jobs and candidates selected, the compatibility score tends to be between the 2.50 and 1.50, with outlier pairs looking to be evenly spread between the extremes of the color scale. This was expected, considering that the data in the candidates and jobs dataframe was randomly generated, however this plot makes me believe that most of the matches computed will not be stable (click [**here**](#gale-shapley) for a refresher) but that is expected since most matches computed in a dynamic environment like the real world tend to follow this pattern.\n",
    "\n",
    "While this heatmap is informative, plotting the features involved in three dimensions might help us deduce more information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53458ab6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "matrix = np.zeros((100, 10))\n",
    "\n",
    "# populate matrix with compatibility score\n",
    "for i in range(100):\n",
    "    for j in range(10):\n",
    "        matrix[i, j] = compute_compatibility(candidates.loc[i], jobs.loc[j])\n",
    "\n",
    "x_indices = np.arange(matrix.shape[0])\n",
    "y_indices = np.arange(matrix.shape[1])\n",
    "X, Y = np.meshgrid(x_indices, y_indices)\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=X.flatten(),\n",
    "    y=Y.flatten(),\n",
    "    z=matrix.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(size=5,color=matrix.flatten(), colorscale='Plasma',  opacity=0.8)\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Candidate ID vs Job ID vs Compatibility',\n",
    "    scene=dict(xaxis_title='Candidate ID', yaxis_title='Job ID', zaxis_title='Compatibility'),\n",
    "    autosize=False,\n",
    "    width=700,\n",
    "    height=700,\n",
    "    margin=dict(l=65, r=50, b=65, t=90)\n",
    ")\n",
    "\n",
    "# plot the green plane\n",
    "x_range = np.linspace(X.min(), X.max(), num=2)\n",
    "y_range = np.linspace(Y.min(), Y.max(), num=2)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "zz = np.full(xx.shape, 1.4)\n",
    "fig.add_trace(go.Surface(x=xx, y=yy, z=zz, colorscale=[[0, 'rgba(0, 204, 102, 0.6)'], [1, 'rgba(0, 204, 102, 0.6)']], showscale=False))\n",
    "\n",
    "# Plot the blue plane\n",
    "x_range = np.linspace(X.min(), X.max(), num=2)\n",
    "y_range = np.linspace(Y.min(), Y.max(), num=2)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "zz = np.full(xx.shape, 2.5) \n",
    "fig.add_trace(go.Surface(x=xx, y=yy, z=zz, colorscale=[[0, 'rgba(0, 153, 255, 0.6)'], [1, 'rgba(0, 153, 255, 0.6)']], showscale=False))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74617fe",
   "metadata": {},
   "source": [
    "From the above 3D scatterplot, we can observe that most of the compatibility scores for this set of inputs score between 1.5 and 2.5 *green-blue plane*, with outliers being found in the bottom 30% for the vast majority and a smaller portion (about 16%) found in the 2.5-3 band. This plot indicates that most of the matches computed will not be [**stable**](#gale-shapley) since the compatibility score tend to be distributed towards the lower end of the 0.0 to 3.0 range of possible values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71d3c82",
   "metadata": {},
   "source": [
    "<a id=\"svm-df-setup\"></a> <br>\n",
    "### Constructing the Dataframe for SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087646a",
   "metadata": {},
   "source": [
    "In order to achieve a higher accuracy when testing the SVM classfier, I will try to extract as many numerical features as possible from the candidates and jobs dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6285679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate the candidates and jobs dataframes with more columns to infere numerical features later on\n",
    "svm_candidates = candidates\n",
    "svm_jobs = jobs\n",
    "\n",
    "svm_candidates[\"Contract length\"] = np.nan\n",
    "svm_candidates[\"Expected Salary\"] = np.nan\n",
    "svm_candidates[\"Location\"] = np.nan\n",
    "\n",
    "svm_jobs[\"Contract length\"] = np.nan\n",
    "svm_jobs[\"Salary\"] = np.nan\n",
    "svm_jobs[\"Location\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random uk towns \n",
    "uk_locations = [\n",
    "    \"London\",\n",
    "    \"Edinburgh\",\n",
    "    \"Manchester\",\n",
    "    \"Bristol\",\n",
    "    \"Birmingham\",\n",
    "    \"Glasgow\",\n",
    "    \"Liverpool\",\n",
    "    \"Cardiff\",\n",
    "    \"Belfast\",\n",
    "    \"Newcastle\"\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b16b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4424b2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add candidate's visa status, salary expectation, location (city), wanted contract length (3, 6, 9, 12 months)\n",
    "for i in range(len(candidates)):\n",
    "    svm_candidates.at[i, \"Contract length\"] = r.choice([3,6,9,12])\n",
    "    svm_candidates.at[i, \"Expected Salary\"] = r.choice([15000, 17500, 20000, 22500, 25000, 27500, 30000])\n",
    "    svm_candidates.at[i, \"Location\"] = r.choice(uk_locations)\n",
    "\n",
    "# add job's salary, contract length (3, 6, 9, 12 months), location (city)\n",
    "for i in range(len(jobs)):\n",
    "    svm_jobs.at[i, \"Contract length\"] = r.choice([3,6,9,12]) \n",
    "    svm_jobs.at[i, \"Salary\"] = r.choice([15000, 17500, 20000, 22500, 25000, 27500, 30000])\n",
    "    svm_jobs.at[i, \"Location\"] = r.choice(uk_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the new svm_candidates dataframe after population\n",
    "try:\n",
    "    svm_candidates.drop(\"Salary\", axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "svm_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the new svm_jobs dataframe after population\n",
    "svm_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf104f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "\n",
    "# define the functions used to infere numerical features in the cell below\n",
    "def compute_field_xp_relevance(candidate_experience, job_experience):\n",
    "    return 1 if candidate_experience == job_experience else 0\n",
    "\n",
    "def compute_contract_length_compatibility(candidateID, jobID):\n",
    "    diff = svm_candidates.iloc[candidateID][\"Contract length\"] - svm_jobs.iloc[jobID][\"Contract length\"]\n",
    "    return diff//3\n",
    "\n",
    "def compute_location_compatibility(candidateID, jobID):\n",
    "    # return a random number between 0 and 500km for now, \n",
    "    # a future improvement will be to calculate the distance between the candidate's city and the job's city\n",
    "    return r.randint(0, 500)\n",
    "\n",
    "def compute_visa_requirements(candidateID, jobID):\n",
    "    distance = compute_location_compatibility(candidateID, jobID)\n",
    "    # if candidate is applying for a job 400+ km away they are more likely to be outside the UK\n",
    "    return 1 if distance > 400 else 0 \n",
    "\n",
    "def compute_offer_outcome(gpa_diff, field_xp_relevance, contract_compatibility, location_compatibility, visa_required, salary_diff):\n",
    "    offer_score = 0\n",
    "    \n",
    "    offer_score += 1 if gpa_diff < 20 else 0\n",
    "    offer_score += contract_compatibility\n",
    "    offer_score += 1 if location_compatibility < 400 else 0\n",
    "    offer_score += 0 if visa_required else 1\n",
    "    offer_score += 1 if salary_diff < 4000 else 0\n",
    "    \n",
    "    return 1 if offer_score >= 3.0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be921079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_df_data = []\n",
    "\n",
    "# populate the table with 500 offers alongside their outcomes \n",
    "for i in range(0, len(candidates)):\n",
    "\n",
    "    # get random candidate and jobs entries and their respective IDs\n",
    "    candidateID, jobID = i, random.randint(0, len(jobs)-1)\n",
    "    candidate, job = svm_candidates.iloc[candidateID], svm_jobs.iloc[jobID]\n",
    "    \n",
    "    # extract the candidate gpa and job's minimum gpa required\n",
    "    candidate_gpa, job_gpa = svm_candidates.iloc[candidateID][\"Score\"], svm_jobs.iloc[jobID][\"MinScore\"]\n",
    "\n",
    "    # compute the compatibility score between the two selected entities\n",
    "    alpha_score = compute_compatibility(candidate, job)\n",
    "    \n",
    "    gpa_diff = candidate_gpa - job_gpa\n",
    "    \n",
    "    field_xp_relevance = compute_field_xp_relevance(svm_candidates.iloc[candidateID][\"Experience\"], svm_jobs.iloc[jobID][\"Field\"])\n",
    "    \n",
    "    contract_compatibility = compute_contract_length_compatibility(candidateID, jobID)\n",
    "    \n",
    "    location_compatibility = compute_location_compatibility(candidateID, jobID)\n",
    "    \n",
    "    visa_required = compute_visa_requirements(candidateID, jobID)\n",
    "    \n",
    "    salary_diff = svm_jobs.iloc[jobID][\"Salary\"] - svm_candidates.iloc[candidateID][\"Expected Salary\"]\n",
    "    \n",
    "    offer_outcome = compute_offer_outcome(\n",
    "        gpa_diff, field_xp_relevance, contract_compatibility, location_compatibility, visa_required, salary_diff\n",
    "    )\n",
    "    \n",
    "    row = [ candidateID, jobID, candidate_gpa, job_gpa, alpha_score, gpa_diff, field_xp_relevance, contract_compatibility, location_compatibility, visa_required,salary_diff, offer_outcome, ]\n",
    "    svm_df_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f825b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_df_cols = [\n",
    "    'candidate ID', \n",
    "    'job ID', \n",
    "    'candidate GPA', \n",
    "    'job min GPA', \n",
    "    'compatibility', \n",
    "    'gpa_diff', \n",
    "    'field-xp relevance', # relevance score for the candidate's experience vs the job's field\n",
    "    'contract length compatibility', # candidate's preferred contract length vs job contract length\n",
    "    'location compatibility', # distance from candidate's location vs location of the job\n",
    "    'visa sponsorship required', # yes/no to whether candidate requires visa sponsorship for the job\n",
    "    'salary expectation-paid diff', # difference of salary expectation for candidate vs job salary\n",
    "    'accepted offer'\n",
    "]\n",
    "\n",
    "svm_df = pd.DataFrame(data=svm_df_data, columns=svm_df_cols)\n",
    "svm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e25ce8",
   "metadata": {},
   "source": [
    "<a id=\"svm-implementation\"></a> <br>\n",
    "### Implementing the SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "611a7a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "4b0d6b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate GPA</th>\n",
       "      <th>job min GPA</th>\n",
       "      <th>compatibility</th>\n",
       "      <th>gpa_diff</th>\n",
       "      <th>field-xp relevance</th>\n",
       "      <th>contract length compatibility</th>\n",
       "      <th>location compatibility</th>\n",
       "      <th>visa sponsorship required</th>\n",
       "      <th>salary expectation-paid diff</th>\n",
       "      <th>accepted offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>90</td>\n",
       "      <td>1.56</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>90</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>70</td>\n",
       "      <td>2.34</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>1.69</td>\n",
       "      <td>-8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>85</td>\n",
       "      <td>1.62</td>\n",
       "      <td>-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>-7500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>2.38</td>\n",
       "      <td>-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>2.17</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>412</td>\n",
       "      <td>0</td>\n",
       "      <td>-5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>86</td>\n",
       "      <td>90</td>\n",
       "      <td>1.32</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>-2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>-7500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     candidate GPA  job min GPA  compatibility  gpa_diff  field-xp relevance  \\\n",
       "0               96           90           1.56         6                   0   \n",
       "1               77           90           2.07       -13                   0   \n",
       "2               86           70           2.34        16                   0   \n",
       "3               82           90           1.69        -8                   1   \n",
       "4               63           85           1.62       -22                   0   \n",
       "..             ...          ...            ...       ...                 ...   \n",
       "995             72           90           2.38       -18                   0   \n",
       "996             71           70           0.85         1                   0   \n",
       "997             92           70           2.17        22                   1   \n",
       "998             86           90           1.32        -4                   0   \n",
       "999             73           80           1.11        -7                   0   \n",
       "\n",
       "     contract length compatibility  location compatibility  \\\n",
       "0                              1.0                     154   \n",
       "1                              1.0                     210   \n",
       "2                              1.0                     196   \n",
       "3                              1.0                     275   \n",
       "4                              0.0                     209   \n",
       "..                             ...                     ...   \n",
       "995                            2.0                     415   \n",
       "996                            2.0                     277   \n",
       "997                           -1.0                     412   \n",
       "998                            3.0                     127   \n",
       "999                            2.0                     173   \n",
       "\n",
       "     visa sponsorship required  salary expectation-paid diff  accepted offer  \n",
       "0                            1                           0.0               1  \n",
       "1                            0                       10000.0               1  \n",
       "2                            1                        2500.0               1  \n",
       "3                            0                       15000.0               1  \n",
       "4                            0                       -7500.0               1  \n",
       "..                         ...                           ...             ...  \n",
       "995                          1                       12500.0               1  \n",
       "996                          0                        2500.0               1  \n",
       "997                          0                       -5000.0               0  \n",
       "998                          0                       -2500.0               1  \n",
       "999                          0                       -7500.0               1  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = svm_df.drop(['candidate ID', 'job ID'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "63bf2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['accepted offer'], axis=1)\n",
    "y = df['accepted offer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "0ef5f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train data and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.95, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "a93a7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "2cb0b21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-44 {color: black;background-color: white;}#sk-container-id-44 pre{padding: 0;}#sk-container-id-44 div.sk-toggleable {background-color: white;}#sk-container-id-44 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-44 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-44 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-44 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-44 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-44 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-44 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-44 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-44 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-44 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-44 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-44 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-44 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-44 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-44 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-44 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-44 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-44 div.sk-item {position: relative;z-index: 1;}#sk-container-id-44 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-44 div.sk-item::before, #sk-container-id-44 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-44 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-44 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-44 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-44 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-44 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-44 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-44 div.sk-label-container {text-align: center;}#sk-container-id-44 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-44 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-44\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" checked><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "c1206bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "50a939cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[253  43]\n",
      " [148 506]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.85      0.73       296\n",
      "           1       0.92      0.77      0.84       654\n",
      "\n",
      "    accuracy                           0.80       950\n",
      "   macro avg       0.78      0.81      0.78       950\n",
      "weighted avg       0.83      0.80      0.81       950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "fec981c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C' : [0.1, 1, 10, 100, 1000, 10000, 100000],\n",
    "    'gamma' : [1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "87e2b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "07f922a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n",
      "[CV 1/5] END ....................C=0.1, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ....................C=0.1, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ....................C=0.1, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ....................C=0.1, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ....................C=0.1, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.0001;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.0001;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.0001;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ...............C=0.1, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, gamma=1e-05;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, gamma=1e-05;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, gamma=1e-05;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ................C=0.1, gamma=1e-06;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ................C=0.1, gamma=1e-06;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ................C=0.1, gamma=1e-06;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ................C=0.1, gamma=1e-06;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ................C=0.1, gamma=1e-06;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ......................C=1, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ......................C=1, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ......................C=1, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ......................C=1, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ......................C=1, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ....................C=1, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ....................C=1, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ....................C=1, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ....................C=1, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ....................C=1, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ...................C=1, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ...................C=1, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ...................C=1, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ...................C=1, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .................C=1, gamma=0.0001;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END .................C=1, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 3/5] END .................C=1, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END .................C=1, gamma=0.0001;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .................C=1, gamma=0.0001;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, gamma=1e-05;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END ..................C=1, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ..................C=1, gamma=1e-06;, score=0.600 total time=   0.0s\n",
      "[CV 3/5] END ..................C=1, gamma=1e-06;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END ..................C=1, gamma=1e-06;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ..................C=1, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ................C=10, gamma=0.0001;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END ................C=10, gamma=0.0001;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ................C=10, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END ................C=10, gamma=0.0001;, score=0.400 total time=   0.0s\n",
      "[CV 5/5] END ................C=10, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .................C=10, gamma=1e-05;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END .................C=10, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 3/5] END .................C=10, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END .................C=10, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END .................C=10, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .................C=10, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END .................C=10, gamma=1e-06;, score=0.600 total time=   0.0s\n",
      "[CV 3/5] END .................C=10, gamma=1e-06;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END .................C=10, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .................C=10, gamma=1e-06;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ..................C=100, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ..................C=100, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=0.600 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .................C=100, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...............C=100, gamma=0.0001;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END ...............C=100, gamma=0.0001;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ...............C=100, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END ...............C=100, gamma=0.0001;, score=0.400 total time=   0.0s\n",
      "[CV 5/5] END ...............C=100, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ................C=100, gamma=1e-05;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END ................C=100, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ................C=100, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ................C=100, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ................C=100, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END ................C=100, gamma=1e-06;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END ................C=100, gamma=1e-06;, score=0.600 total time=   0.0s\n",
      "[CV 3/5] END ................C=100, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ................C=100, gamma=1e-06;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ................C=100, gamma=1e-06;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ..............C=1000, gamma=0.0001;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END ..............C=1000, gamma=0.0001;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ..............C=1000, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END ..............C=1000, gamma=0.0001;, score=0.400 total time=   0.0s\n",
      "[CV 5/5] END ..............C=1000, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...............C=1000, gamma=1e-05;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END ...............C=1000, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ...............C=1000, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ...............C=1000, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ...............C=1000, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...............C=1000, gamma=1e-06;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END ...............C=1000, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ...............C=1000, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ...............C=1000, gamma=1e-06;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END ...............C=1000, gamma=1e-06;, score=0.400 total time=   0.0s\n",
      "[CV 1/5] END ..................C=10000, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ..................C=10000, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ..................C=10000, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ..................C=10000, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ..................C=10000, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ................C=10000, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ................C=10000, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ................C=10000, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ................C=10000, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ................C=10000, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...............C=10000, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ...............C=10000, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ...............C=10000, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ...............C=10000, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ...............C=10000, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ..............C=10000, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END ..............C=10000, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ..............C=10000, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ..............C=10000, gamma=0.001;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ..............C=10000, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .............C=10000, gamma=0.0001;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END .............C=10000, gamma=0.0001;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END .............C=10000, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END .............C=10000, gamma=0.0001;, score=0.400 total time=   0.0s\n",
      "[CV 5/5] END .............C=10000, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ..............C=10000, gamma=1e-05;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END ..............C=10000, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ..............C=10000, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ..............C=10000, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END ..............C=10000, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ..............C=10000, gamma=1e-06;, score=0.300 total time=   0.0s\n",
      "[CV 2/5] END ..............C=10000, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ..............C=10000, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END ..............C=10000, gamma=1e-06;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END ..............C=10000, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END .................C=100000, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END .................C=100000, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END .................C=100000, gamma=1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END .................C=100000, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END .................C=100000, gamma=1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ...............C=100000, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ...............C=100000, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ...............C=100000, gamma=0.1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ...............C=100000, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ...............C=100000, gamma=0.1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ..............C=100000, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END ..............C=100000, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ..............C=100000, gamma=0.01;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ..............C=100000, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ..............C=100000, gamma=0.01;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .............C=100000, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END .............C=100000, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END .............C=100000, gamma=0.001;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END .............C=100000, gamma=0.001;, score=0.500 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .............C=100000, gamma=0.001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END ............C=100000, gamma=0.0001;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END ............C=100000, gamma=0.0001;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ............C=100000, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END ............C=100000, gamma=0.0001;, score=0.400 total time=   0.0s\n",
      "[CV 5/5] END ............C=100000, gamma=0.0001;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .............C=100000, gamma=1e-05;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END .............C=100000, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END .............C=100000, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END .............C=100000, gamma=1e-05;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END .............C=100000, gamma=1e-05;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .............C=100000, gamma=1e-06;, score=0.300 total time=   0.0s\n",
      "[CV 2/5] END .............C=100000, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END .............C=100000, gamma=1e-06;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END .............C=100000, gamma=1e-06;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END .............C=100000, gamma=1e-06;, score=0.500 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-45 {color: black;background-color: white;}#sk-container-id-45 pre{padding: 0;}#sk-container-id-45 div.sk-toggleable {background-color: white;}#sk-container-id-45 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-45 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-45 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-45 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-45 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-45 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-45 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-45 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-45 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-45 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-45 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-45 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-45 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-45 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-45 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-45 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-45 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-45 div.sk-item {position: relative;z-index: 1;}#sk-container-id-45 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-45 div.sk-item::before, #sk-container-id-45 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-45 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-45 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-45 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-45 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-45 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-45 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-45 div.sk-label-container {text-align: center;}#sk-container-id-45 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-45 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-45\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000, 10000, 100000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000, 10000, 100000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000, 10000, 100000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "84157e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 1}"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "f3c09949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-46 {color: black;background-color: white;}#sk-container-id-46 pre{padding: 0;}#sk-container-id-46 div.sk-toggleable {background-color: white;}#sk-container-id-46 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-46 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-46 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-46 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-46 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-46 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-46 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-46 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-46 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-46 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-46 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-46 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-46 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-46 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-46 div.sk-item {position: relative;z-index: 1;}#sk-container-id-46 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-46 div.sk-item::before, #sk-container-id-46 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-46 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-46 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-46 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-46 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-46 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-46 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-46 div.sk-label-container {text-align: center;}#sk-container-id-46 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-46 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-46\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" checked><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=1)"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "83da8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "82b94501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[253  43]\n",
      " [148 506]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.85      0.73       296\n",
      "           1       0.92      0.77      0.84       654\n",
      "\n",
      "    accuracy                           0.80       950\n",
      "   macro avg       0.78      0.81      0.78       950\n",
      "weighted avg       0.83      0.80      0.81       950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af67f6e",
   "metadata": {},
   "source": [
    "<a id=\"random-forest\"></a> <br>\n",
    "# Random Forest\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16645ade",
   "metadata": {},
   "source": [
    "<a id=\"lambda-mart\"></a> <br>\n",
    "# LambdaMART Algorithm\n",
    "[back to top](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194f36a",
   "metadata": {},
   "source": [
    "<a id=\"project-conclusion\"></a> <br>\n",
    "# Project Conclusion\n",
    "[back to top](#table-of-contents)\n",
    "\n",
    "\n",
    "\n",
    "SKILLPILOT IDEA – could be in conclusion as one of the considered approaches but not implemented due to reasons outlined below\n",
    "Exponential time complexity\n",
    "Use a heuristic search for optimal pairing combo across pool \n",
    "Heuristic being number of stable pairings or clusters \n",
    "Reduce complexity by aiming to cluster points based on attributes on their own \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
